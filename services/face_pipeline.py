"""
ì–¼êµ´ ì¸ì‹ íŒŒì´í”„ë¼ì¸
ì´ë¯¸ì§€ â†’ ì–¼êµ´ ê²€ì¶œ â†’ ì–¼êµ´ crop/ì •ê·œí™” â†’ ArcFace ìž„ë² ë”© â†’ ê²°ê³¼ ë°˜í™˜
"""

import cv2
import numpy as np
import logging
import time
from typing import List, Dict, Optional, Tuple
import os

from models.retinaface import RetinaFaceDetector
from models.arcface import ArcFaceRecognizer, EmbeddingDatabase

logger = logging.getLogger(__name__)

class FacePipeline:
    """í†µí•© ì–¼êµ´ ì¸ì‹ íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, gpu_enabled: bool = True, model_path: str = None, embeddings_path: str = None):
        """
        íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            gpu_enabled: GPU ì‚¬ìš© ì—¬ë¶€
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            embeddings_path: ìž„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
        """
        self.gpu_enabled = gpu_enabled
        self.model_path = model_path
        self.embeddings_path = embeddings_path
        
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
        if not self.model_path:
            self.model_path = "models/weights"
        if not self.embeddings_path:
            self.embeddings_path = "data/embeddings"
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.detector = None
        self.recognizer = None
        self.embeddings_db = None
        
        # ì„¤ì •
        self.detection_confidence = 0.5
        self.similarity_threshold = 0.6
        
        self._initialize_models()
    
    def _initialize_models(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # RetinaFace ê²€ì¶œê¸° ì´ˆê¸°í™”
            detector_path = os.path.join(self.model_path, "det_10g.onnx")
            if os.path.exists(detector_path):
                self.detector = RetinaFaceDetector(
                    model_path=detector_path,
                    gpu_enabled=self.gpu_enabled,
                    confidence_threshold=self.detection_confidence
                )
                logger.info("âœ… RetinaFace ê²€ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸  ê²€ì¶œê¸° ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {detector_path}")
            
            # ArcFace ì¸ì‹ê¸° ì´ˆê¸°í™”
            recognizer_path = os.path.join(self.model_path, "w600k_r50.onnx")
            if os.path.exists(recognizer_path):
                self.recognizer = ArcFaceRecognizer(
                    model_path=recognizer_path,
                    gpu_enabled=self.gpu_enabled
                )
                logger.info("âœ… ArcFace ì¸ì‹ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸  ì¸ì‹ê¸° ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {recognizer_path}")
            
            # ìž„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
            embeddings_file = os.path.join(self.embeddings_path, "all_embeddings.json")
            suspects_file = "data/suspects/metadata/suspect_profiles.json"
            
            if os.path.exists(embeddings_file) and os.path.exists(suspects_file):
                self.embeddings_db = EmbeddingDatabase(
                    embeddings_path=embeddings_file,
                    suspects_metadata_path=suspects_file
                )
                logger.info("âœ… ìž„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸  ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def process_image(self, image: np.ndarray, target_suspect_id: str = None) -> List[Dict]:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ì–¼êµ´ ì¸ì‹ ìˆ˜í–‰
        
        Args:
            image: ìž…ë ¥ ì´ë¯¸ì§€ (BGR)
            target_suspect_id: íŠ¹ì • ìš©ì˜ìž ID (ì„ íƒì‚¬í•­)
            
        Returns:
            ì¸ì‹ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        start_time = time.time()
        results = []
        
        try:
            if self.detector is None:
                raise RuntimeError("ê²€ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # 1. ì–¼êµ´ ê²€ì¶œ
            detections = self.detector.detect_faces(image)
            logger.debug(f"ðŸ” {len(detections)}ê°œì˜ ì–¼êµ´ ê²€ì¶œë¨")
            
            if not detections:
                return []
            
            # 2. ê° ê²€ì¶œëœ ì–¼êµ´ì— ëŒ€í•´ ì¸ì‹ ìˆ˜í–‰
            for i, detection in enumerate(detections):
                try:
                    # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
                    face_roi = self.detector.extract_face_roi(image, detection['bbox'])
                    if face_roi is None:
                        continue
                    
                    # ì–¼êµ´ ì¸ì‹ ìˆ˜í–‰
                    recognition_result = self._recognize_face(
                        face_roi, 
                        target_suspect_id=target_suspect_id
                    )
                    
                    # ê²°ê³¼ êµ¬ì„±
                    result = {
                        'face_id': i,
                        'face_bbox': detection['bbox'],
                        'detection_confidence': detection['confidence'],
                        'landmarks': detection.get('landmarks'),
                        'suspect_match': recognition_result,
                        'processing_time': time.time() - start_time
                    }
                    
                    results.append(result)
                    
                except Exception as e:
                    logger.error(f"ì–¼êµ´ {i} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    continue
            
            logger.info(f"ðŸŽ¯ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ì–¼êµ´, {time.time() - start_time:.2f}ì´ˆ")
            
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return results
    
    def _recognize_face(self, face_image: np.ndarray, target_suspect_id: str = None) -> Optional[Dict]:
        """
        ì–¼êµ´ ì¸ì‹ ìˆ˜í–‰
        
        Args:
            face_image: ì–¼êµ´ ì´ë¯¸ì§€
            target_suspect_id: íŠ¹ì • ìš©ì˜ìž ID
            
        Returns:
            ì¸ì‹ ê²°ê³¼
        """
        try:
            if self.recognizer is None or self.embeddings_db is None:
                return None
            
            # ìž„ë² ë”© ì¶”ì¶œ
            face_embedding = self.recognizer.extract_embedding(face_image)
            if face_embedding is None:
                return None
            
            # ë°ì´í„°ë² ì´ìŠ¤ì™€ ë¹„êµ
            if target_suspect_id:
                # íŠ¹ì • ìš©ì˜ìžì™€ ë¹„êµ
                target_embedding = self.embeddings_db.get_embedding(target_suspect_id)
                if target_embedding is not None:
                    similarity = self.recognizer.compare_embeddings(
                        face_embedding, target_embedding
                    )
                    
                    if similarity >= self.similarity_threshold:
                        suspect_info = self.embeddings_db.get_suspect_info(target_suspect_id)
                        
                        return {
                            'suspect_id': target_suspect_id,
                            'name': suspect_info.get('name', 'Unknown') if suspect_info else 'Unknown',
                            'similarity': similarity,
                            'confidence': similarity * 100,
                            'is_criminal': suspect_info.get('is_criminal', False) if suspect_info else False,
                            'risk_level': suspect_info.get('risk_level', 'unknown') if suspect_info else 'unknown',
                            'criminal_record': suspect_info.get('criminal_record', []) if suspect_info else [],
                            'category': suspect_info.get('role', 'unknown') if suspect_info else 'unknown'
                        }
            else:
                # ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ì™€ ë¹„êµ
                all_embeddings = self.embeddings_db.get_all_embeddings()
                best_match = self.recognizer.find_most_similar(
                    face_embedding, all_embeddings, self.similarity_threshold
                )
                
                if best_match:
                    suspect_info = self.embeddings_db.get_suspect_info(best_match['suspect_id'])
                    
                    return {
                        'suspect_id': best_match['suspect_id'],
                        'name': suspect_info.get('name', 'Unknown') if suspect_info else 'Unknown',
                        'similarity': best_match['similarity'],
                        'confidence': best_match['confidence'],
                        'is_criminal': suspect_info.get('is_criminal', False) if suspect_info else False,
                        'risk_level': suspect_info.get('risk_level', 'unknown') if suspect_info else 'unknown',
                        'criminal_record': suspect_info.get('criminal_record', []) if suspect_info else [],
                        'category': suspect_info.get('role', 'unknown') if suspect_info else 'unknown'
                    }
            
            return None
            
        except Exception as e:
            logger.error(f"ì–¼êµ´ ì¸ì‹ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def process_video(self, video_path: str, target_suspect_id: str = None, 
                     frame_interval: int = 30) -> List[Dict]:
        """
        ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì–¼êµ´ ì¸ì‹ ìˆ˜í–‰
        
        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            target_suspect_id: íŠ¹ì • ìš©ì˜ìž ID
            frame_interval: í”„ë ˆìž„ ê°„ê²© (ëª‡ í”„ë ˆìž„ë§ˆë‹¤ ì²˜ë¦¬í• ì§€)
            
        Returns:
            í”„ë ˆìž„ë³„ ì¸ì‹ ê²°ê³¼
        """
        video_results = []
        
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise ValueError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            logger.info(f"ðŸ“¹ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œìž‘: {total_frames} í”„ë ˆìž„, {fps} FPS")
            
            frame_number = 0
            processed_frames = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # ì§€ì •ëœ ê°„ê²©ë§ˆë‹¤ í”„ë ˆìž„ ì²˜ë¦¬
                if frame_number % frame_interval == 0:
                    timestamp = frame_number / fps
                    
                    # ì–¼êµ´ ì¸ì‹ ìˆ˜í–‰
                    frame_results = self.process_image(frame, target_suspect_id)
                    
                    if frame_results:
                        video_results.append({
                            'frame_number': frame_number,
                            'timestamp': timestamp,
                            'detections': frame_results
                        })
                    
                    processed_frames += 1
                    
                    if processed_frames % 10 == 0:
                        logger.info(f"ðŸŽ¬ ì²˜ë¦¬ ì¤‘: {processed_frames} / {total_frames // frame_interval} í”„ë ˆìž„")
                
                frame_number += 1
            
            cap.release()
            
            logger.info(f"âœ… ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {len(video_results)}ê°œ í”„ë ˆìž„ì—ì„œ ê²€ì¶œ")
            
        except Exception as e:
            logger.error(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        return video_results
    
    def update_threshold(self, detection_threshold: float = None, 
                        similarity_threshold: float = None):
        """ìž„ê³„ê°’ ì—…ë°ì´íŠ¸"""
        if detection_threshold is not None:
            self.detection_confidence = detection_threshold
            if self.detector:
                self.detector.confidence_threshold = detection_threshold
        
        if similarity_threshold is not None:
            self.similarity_threshold = similarity_threshold
    
    def get_system_info(self) -> Dict:
        """ì‹œìŠ¤í…œ ì •ë³´ ì¡°íšŒ"""
        return {
            'detector_loaded': self.detector is not None,
            'recognizer_loaded': self.recognizer is not None,
            'database_loaded': self.embeddings_db is not None,
            'gpu_enabled': self.gpu_enabled,
            'detection_confidence': self.detection_confidence,
            'similarity_threshold': self.similarity_threshold,
            'suspects_count': len(self.embeddings_db) if self.embeddings_db else 0
        }