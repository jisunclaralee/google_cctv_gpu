"""
ArcFace ì–¼êµ´ ì¸ì‹ ëª¨ë“ˆ
InsightFace ê¸°ë°˜ ì–¼êµ´ ì„ë² ë”© ìƒì„±
"""

import cv2
import numpy as np
import onnxruntime
import torch
import logging
from typing import List, Optional, Dict
import os
import json

logger = logging.getLogger(__name__)

class ArcFaceRecognizer:
    """ArcFace ê¸°ë°˜ ì–¼êµ´ ì¸ì‹ê¸°"""
    
    def __init__(self, model_path: str, gpu_enabled: bool = True):
        """
        ArcFace ì¸ì‹ê¸° ì´ˆê¸°í™”
        
        Args:
            model_path: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            gpu_enabled: GPU ì‚¬ìš© ì—¬ë¶€
        """
        self.model_path = model_path
        self.gpu_enabled = gpu_enabled and torch.cuda.is_available()
        self.session = None
        self.input_size = (112, 112)  # ArcFace í‘œì¤€ ì…ë ¥ í¬ê¸°
        self.embedding_dim = 512  # ArcFace ì„ë² ë”© ì°¨ì›
        
        self._load_model()
    
    def _load_model(self):
        """ONNX ëª¨ë¸ ë¡œë“œ"""
        try:
            if not os.path.exists(self.model_path):
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
            
            # ONNX Runtime ì„¤ì •
            providers = []
            if self.gpu_enabled:
                providers.append('CUDAExecutionProvider')
            providers.append('CPUExecutionProvider')
            
            self.session = onnxruntime.InferenceSession(
                self.model_path, 
                providers=providers
            )
            
            # ì…ë ¥/ì¶œë ¥ ì •ë³´ í™•ì¸
            self.input_name = self.session.get_inputs()[0].name
            self.output_name = self.session.get_outputs()[0].name
            
            # ì…ë ¥ í¬ê¸° í™•ì¸ (ë™ì ìœ¼ë¡œ ì¡°ì •)
            input_shape = self.session.get_inputs()[0].shape
            if len(input_shape) >= 3:
                self.input_size = (input_shape[2], input_shape[3])
            
            logger.info(f"âœ… ArcFace ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
            logger.info(f"ğŸ–¥ï¸  ì‹¤í–‰ í™˜ê²½: {'GPU' if self.gpu_enabled else 'CPU'}")
            logger.info(f"ğŸ“ ì…ë ¥ í¬ê¸°: {self.input_size}")
            
        except Exception as e:
            logger.error(f"âŒ ArcFace ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def preprocess_face(self, face_image: np.ndarray) -> np.ndarray:
        """
        ì–¼êµ´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        
        Args:
            face_image: ì–¼êµ´ ì´ë¯¸ì§€ (BGR)
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€
        """
        try:
            # í¬ê¸° ì¡°ì •
            face_resized = cv2.resize(face_image, self.input_size)
            
            # ì •ê·œí™” ë° ì°¨ì› ë³€í™˜
            blob = cv2.dnn.blobFromImage(
                face_resized,
                scalefactor=1.0/127.5,
                size=self.input_size,
                mean=(127.5, 127.5, 127.5),
                swapRB=True
            )
            
            return blob
            
        except Exception as e:
            logger.error(f"ì–¼êµ´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def extract_embedding(self, face_image: np.ndarray) -> Optional[np.ndarray]:
        """
        ì–¼êµ´ ì´ë¯¸ì§€ì—ì„œ ì„ë² ë”© ë²¡í„° ì¶”ì¶œ
        
        Args:
            face_image: ì–¼êµ´ ì´ë¯¸ì§€ (BGR)
            
        Returns:
            ì„ë² ë”© ë²¡í„° (512ì°¨ì›)
        """
        if self.session is None:
            raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            # ì „ì²˜ë¦¬
            blob = self.preprocess_face(face_image)
            if blob is None:
                return None
            
            # ì¶”ë¡  ì‹¤í–‰
            embedding = self.session.run(
                [self.output_name], 
                {self.input_name: blob}
            )[0]
            
            # ì •ê·œí™”
            embedding = embedding.flatten()
            embedding = embedding / np.linalg.norm(embedding)
            
            return embedding
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def compare_embeddings(self, embedding1: np.ndarray, embedding2: np.ndarray) -> float:
        """
        ë‘ ì„ë² ë”© ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            embedding1, embedding2: ë¹„êµí•  ì„ë² ë”© ë²¡í„°
            
        Returns:
            ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0~1)
        """
        try:
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarity = np.dot(embedding1, embedding2)
            
            # í´ë¦¬í•‘ (ìˆ˜ì¹˜ ì•ˆì •ì„±)
            similarity = np.clip(similarity, -1.0, 1.0)
            
            # 0~1 ë²”ìœ„ë¡œ ë³€í™˜
            similarity = (similarity + 1.0) / 2.0
            
            return float(similarity)
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ë¹„êµ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return 0.0
    
    def find_most_similar(self, query_embedding: np.ndarray, 
                         database_embeddings: Dict[str, np.ndarray],
                         threshold: float = 0.6) -> Optional[Dict]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ì„ë² ë”© ì°¾ê¸°
        
        Args:
            query_embedding: ì¿¼ë¦¬ ì„ë² ë”©
            database_embeddings: ë°ì´í„°ë² ì´ìŠ¤ ì„ë² ë”©ë“¤
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
            
        Returns:
            ê°€ì¥ ìœ ì‚¬í•œ ê²°ê³¼ ì •ë³´
        """
        try:
            best_match = None
            best_similarity = 0.0
            
            for suspect_id, db_embedding in database_embeddings.items():
                similarity = self.compare_embeddings(query_embedding, db_embedding)
                
                if similarity > best_similarity and similarity >= threshold:
                    best_similarity = similarity
                    best_match = {
                        'suspect_id': suspect_id,
                        'similarity': similarity,
                        'confidence': similarity * 100
                    }
            
            return best_match
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

class EmbeddingDatabase:
    """ì–¼êµ´ ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬"""
    
    def __init__(self, embeddings_path: str, suspects_metadata_path: str):
        """
        ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            embeddings_path: ì„ë² ë”© íŒŒì¼ ê²½ë¡œ
            suspects_metadata_path: ìš©ì˜ì ë©”íƒ€ë°ì´í„° ê²½ë¡œ
        """
        self.embeddings_path = embeddings_path
        self.suspects_metadata_path = suspects_metadata_path
        self.embeddings = {}
        self.suspects_info = {}
        
        self._load_database()
    
    def _load_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ"""
        try:
            # ì„ë² ë”© ë°ì´í„° ë¡œë“œ
            if os.path.exists(self.embeddings_path):
                with open(self.embeddings_path, 'r', encoding='utf-8') as f:
                    embeddings_data = json.load(f)
                
                # numpy ë°°ì—´ë¡œ ë³€í™˜
                for suspect_id, embedding_list in embeddings_data.items():
                    if suspect_id != 'metadata':
                        self.embeddings[suspect_id] = np.array(embedding_list)
                
                logger.info(f"âœ… ì„ë² ë”© ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.embeddings)}ëª…")
            
            # ìš©ì˜ì ë©”íƒ€ë°ì´í„° ë¡œë“œ
            if os.path.exists(self.suspects_metadata_path):
                with open(self.suspects_metadata_path, 'r', encoding='utf-8') as f:
                    suspects_data = json.load(f)
                
                # ìš©ì˜ì ì •ë³´ ì¸ë±ì‹±
                for suspect in suspects_data.get('suspects', []):
                    self.suspects_info[suspect['id']] = suspect
                
                logger.info(f"âœ… ìš©ì˜ì ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.suspects_info)}ëª…")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def get_embedding(self, suspect_id: str) -> Optional[np.ndarray]:
        """ìš©ì˜ì ì„ë² ë”© ì¡°íšŒ"""
        return self.embeddings.get(suspect_id)
    
    def get_suspect_info(self, suspect_id: str) -> Optional[Dict]:
        """ìš©ì˜ì ì •ë³´ ì¡°íšŒ"""
        return self.suspects_info.get(suspect_id)
    
    def add_embedding(self, suspect_id: str, embedding: np.ndarray):
        """ì„ë² ë”© ì¶”ê°€"""
        self.embeddings[suspect_id] = embedding
    
    def save_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥"""
        try:
            # ì„ë² ë”©ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            embeddings_to_save = {}
            for suspect_id, embedding in self.embeddings.items():
                embeddings_to_save[suspect_id] = embedding.tolist()
            
            # ë©”íƒ€ë°ì´í„° ì¶”ê°€
            embeddings_to_save['metadata'] = {
                'saved_date': str(np.datetime64('now')),
                'total_embeddings': len(self.embeddings)
            }
            
            with open(self.embeddings_path, 'w', encoding='utf-8') as f:
                json.dump(embeddings_to_save, f, indent=2, ensure_ascii=False)
            
            logger.info(f"âœ… ì„ë² ë”© ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ: {self.embeddings_path}")
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    def get_all_embeddings(self) -> Dict[str, np.ndarray]:
        """ëª¨ë“  ì„ë² ë”© ë°˜í™˜"""
        return self.embeddings.copy()
    
    def __len__(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸° ë°˜í™˜"""
        return len(self.embeddings)