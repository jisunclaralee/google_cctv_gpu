"""
RetinaFace ì–¼êµ´ ê²€ì¶œê¸° ëª¨ë“ˆ
InsightFace ê¸°ë°˜ PyTorch/ONNX ê²€ì¶œê¸°
"""

import cv2
import numpy as np
import onnxruntime
import torch
import logging
from typing import List, Tuple, Optional
import os

logger = logging.getLogger(__name__)

class RetinaFaceDetector:
    """RetinaFace ê¸°ë°˜ ì–¼êµ´ ê²€ì¶œê¸°"""
    
    def __init__(self, model_path: str, gpu_enabled: bool = True, confidence_threshold: float = 0.5):
        """
        RetinaFace ê²€ì¶œê¸° ì´ˆê¸°í™”
        
        Args:
            model_path: ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            gpu_enabled: GPU ì‚¬ìš© ì—¬ë¶€
            confidence_threshold: ê²€ì¶œ ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
        self.gpu_enabled = gpu_enabled and torch.cuda.is_available()
        self.session = None
        self.input_size = (640, 640)  # RetinaFace ê¸°ë³¸ ì…ë ¥ í¬ê¸°
        
        self._load_model()
    
    def _load_model(self):
        """ONNX ëª¨ë¸ ë¡œë“œ"""
        try:
            if not os.path.exists(self.model_path):
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
            
            # ONNX Runtime ì„¤ì •
            providers = []
            if self.gpu_enabled:
                providers.append('CUDAExecutionProvider')
            providers.append('CPUExecutionProvider')
            
            self.session = onnxruntime.InferenceSession(
                self.model_path, 
                providers=providers
            )
            
            # ì…ë ¥/ì¶œë ¥ ì´ë¦„ í™•ì¸
            self.input_name = self.session.get_inputs()[0].name
            self.output_names = [output.name for output in self.session.get_outputs()]
            
            logger.info(f"âœ… RetinaFace ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {self.model_path}")
            logger.info(f"ğŸ–¥ï¸  ì‹¤í–‰ í™˜ê²½: {'GPU' if self.gpu_enabled else 'CPU'}")
            
        except Exception as e:
            logger.error(f"âŒ RetinaFace ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def preprocess_image(self, image: np.ndarray) -> Tuple[np.ndarray, float, float]:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR)
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€, x ìŠ¤ì¼€ì¼, y ìŠ¤ì¼€ì¼
        """
        height, width = image.shape[:2]
        
        # ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
        scale_x = self.input_size[0] / width
        scale_y = self.input_size[1] / height
        scale = min(scale_x, scale_y)
        
        new_width = int(width * scale)
        new_height = int(height * scale)
        
        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
        resized_image = cv2.resize(image, (new_width, new_height))
        
        # íŒ¨ë”© ì¶”ê°€ (ì¤‘ì•™ ì •ë ¬)
        pad_x = (self.input_size[0] - new_width) // 2
        pad_y = (self.input_size[1] - new_height) // 2
        
        padded_image = np.zeros((self.input_size[1], self.input_size[0], 3), dtype=np.uint8)
        padded_image[pad_y:pad_y+new_height, pad_x:pad_x+new_width] = resized_image
        
        # ì •ê·œí™” ë° ì°¨ì› ë³€í™˜
        blob = cv2.dnn.blobFromImage(
            padded_image, 
            scalefactor=1.0/127.5, 
            size=self.input_size,
            mean=(127.5, 127.5, 127.5), 
            swapRB=True
        )
        
        return blob, scale, scale
    
    def postprocess_outputs(self, outputs: List[np.ndarray], scale_x: float, scale_y: float, 
                          original_shape: Tuple[int, int]) -> List[dict]:
        """
        ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬
        
        Args:
            outputs: ëª¨ë¸ ì¶œë ¥
            scale_x, scale_y: ìŠ¤ì¼€ì¼ë§ íŒ©í„°
            original_shape: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (height, width)
            
        Returns:
            ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        detections = []
        
        # RetinaFace ì¶œë ¥ íŒŒì‹± (êµ¬í˜„ì— ë”°ë¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        if len(outputs) >= 3:
            boxes = outputs[0]  # ë°”ìš´ë”© ë°•ìŠ¤
            scores = outputs[1]  # ì‹ ë¢°ë„
            landmarks = outputs[2] if len(outputs) > 2 else None  # ëœë“œë§ˆí¬
            
            # ê° ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬
            for i in range(boxes.shape[0]):
                confidence = float(scores[i])
                
                if confidence >= self.confidence_threshold:
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³µì›
                    x1, y1, x2, y2 = boxes[i]
                    
                    # ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜
                    x1 = int(x1 / scale_x)
                    y1 = int(y1 / scale_y)
                    x2 = int(x2 / scale_x)
                    y2 = int(y2 / scale_y)
                    
                    # ê²½ê³„ê°’ í´ë¦¬í•‘
                    x1 = max(0, min(x1, original_shape[1]))
                    y1 = max(0, min(y1, original_shape[0]))
                    x2 = max(0, min(x2, original_shape[1]))
                    y2 = max(0, min(y2, original_shape[0]))
                    
                    detection = {
                        'bbox': [x1, y1, x2 - x1, y2 - y1],  # [x, y, width, height]
                        'confidence': confidence,
                        'landmarks': None
                    }
                    
                    # ëœë“œë§ˆí¬ê°€ ìˆëŠ” ê²½ìš° ì¶”ê°€
                    if landmarks is not None and i < landmarks.shape[0]:
                        lm = landmarks[i].reshape(-1, 2)
                        # ì¢Œí‘œ ë³€í™˜
                        lm[:, 0] = lm[:, 0] / scale_x
                        lm[:, 1] = lm[:, 1] / scale_y
                        detection['landmarks'] = lm.tolist()
                    
                    detections.append(detection)
        
        return detections
    
    def detect_faces(self, image: np.ndarray) -> List[dict]:
        """
        ì–¼êµ´ ê²€ì¶œ ì‹¤í–‰
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR)
            
        Returns:
            ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if self.session is None:
            raise RuntimeError("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        try:
            # ì „ì²˜ë¦¬
            blob, scale_x, scale_y = self.preprocess_image(image)
            
            # ì¶”ë¡  ì‹¤í–‰
            outputs = self.session.run(
                self.output_names, 
                {self.input_name: blob}
            )
            
            # í›„ì²˜ë¦¬
            detections = self.postprocess_outputs(
                outputs, scale_x, scale_y, image.shape[:2]
            )
            
            logger.debug(f"ğŸ” {len(detections)}ê°œì˜ ì–¼êµ´ ê²€ì¶œë¨")
            return detections
            
        except Exception as e:
            logger.error(f"ì–¼êµ´ ê²€ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def extract_face_roi(self, image: np.ndarray, bbox: List[int], 
                        padding: float = 0.2) -> Optional[np.ndarray]:
        """
        ë°”ìš´ë”© ë°•ìŠ¤ì—ì„œ ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            bbox: ë°”ìš´ë”© ë°•ìŠ¤ [x, y, width, height]
            padding: íŒ¨ë”© ë¹„ìœ¨
            
        Returns:
            ì¶”ì¶œëœ ì–¼êµ´ ì´ë¯¸ì§€
        """
        try:
            x, y, w, h = bbox
            
            # íŒ¨ë”© ì¶”ê°€
            pad_x = int(w * padding / 2)
            pad_y = int(h * padding / 2)
            
            x1 = max(0, x - pad_x)
            y1 = max(0, y - pad_y)
            x2 = min(image.shape[1], x + w + pad_x)
            y2 = min(image.shape[0], y + h + pad_y)
            
            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
            face_roi = image[y1:y2, x1:x2]
            
            if face_roi.size == 0:
                return None
                
            return face_roi
            
        except Exception as e:
            logger.error(f"ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None